{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":38257,"databundleVersionId":4319132,"sourceType":"competition"}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imports\nimport random\nimport shutil\nimport math\n\nfrom sklearn.cluster import KMeans\n\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf \nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2024-01-23T19:01:29.249698Z","iopub.execute_input":"2024-01-23T19:01:29.250658Z","iopub.status.idle":"2024-01-23T19:01:44.958818Z","shell.execute_reply.started":"2024-01-23T19:01:29.250616Z","shell.execute_reply":"2024-01-23T19:01:44.957579Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = '/kaggle/input/icecube-neutrinos-in-deep-ice/train/batch_1.parquet'\ndf = pd.read_parquet(data)\ndf.head(20)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:21.439461Z","iopub.execute_input":"2024-01-20T23:13:21.439823Z","iopub.status.idle":"2024-01-20T23:13:24.691184Z","shell.execute_reply.started":"2024-01-20T23:13:21.439786Z","shell.execute_reply":"2024-01-20T23:13:24.689732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:24.692742Z","iopub.execute_input":"2024-01-20T23:13:24.693250Z","iopub.status.idle":"2024-01-20T23:13:28.516866Z","shell.execute_reply.started":"2024-01-20T23:13:24.693202Z","shell.execute_reply":"2024-01-20T23:13:28.515465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:28.521178Z","iopub.execute_input":"2024-01-20T23:13:28.522038Z","iopub.status.idle":"2024-01-20T23:13:28.543427Z","shell.execute_reply.started":"2024-01-20T23:13:28.521998Z","shell.execute_reply":"2024-01-20T23:13:28.541774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:28.545630Z","iopub.execute_input":"2024-01-20T23:13:28.546143Z","iopub.status.idle":"2024-01-20T23:13:28.557091Z","shell.execute_reply.started":"2024-01-20T23:13:28.546091Z","shell.execute_reply":"2024-01-20T23:13:28.555537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.index","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:28.558793Z","iopub.execute_input":"2024-01-20T23:13:28.559289Z","iopub.status.idle":"2024-01-20T23:13:28.571485Z","shell.execute_reply.started":"2024-01-20T23:13:28.559241Z","shell.execute_reply":"2024-01-20T23:13:28.569849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:28.573462Z","iopub.execute_input":"2024-01-20T23:13:28.573997Z","iopub.status.idle":"2024-01-20T23:13:28.737461Z","shell.execute_reply.started":"2024-01-20T23:13:28.573949Z","shell.execute_reply":"2024-01-20T23:13:28.736462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sensor_id'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:28.738942Z","iopub.execute_input":"2024-01-20T23:13:28.739850Z","iopub.status.idle":"2024-01-20T23:13:28.927870Z","shell.execute_reply.started":"2024-01-20T23:13:28.739807Z","shell.execute_reply":"2024-01-20T23:13:28.926620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sensor_data = '/kaggle/input/icecube-neutrinos-in-deep-ice/sensor_geometry.csv'\ndf_sensor = pd.read_csv(sensor_data)\ndf_sensor.head(20)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:28.929480Z","iopub.execute_input":"2024-01-20T23:13:28.930961Z","iopub.status.idle":"2024-01-20T23:13:29.100193Z","shell.execute_reply.started":"2024-01-20T23:13:28.930919Z","shell.execute_reply":"2024-01-20T23:13:29.098736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sensor['sensor_id'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:29.101433Z","iopub.execute_input":"2024-01-20T23:13:29.101819Z","iopub.status.idle":"2024-01-20T23:13:29.112233Z","shell.execute_reply.started":"2024-01-20T23:13:29.101786Z","shell.execute_reply":"2024-01-20T23:13:29.110795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"One thing that really piqued my interest when I first read paper detailing the 1st place solution was the minimal amount of preprocessing used by the winning team. Their results come entirely from the efficiency and sophistication of their architecture, and I found that facsinating. ","metadata":{}},{"cell_type":"code","source":"# os.mkdir('/kaggle/working/train_raw')","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:29.114060Z","iopub.execute_input":"2024-01-20T23:13:29.114583Z","iopub.status.idle":"2024-01-20T23:13:29.123942Z","shell.execute_reply.started":"2024-01-20T23:13:29.114542Z","shell.execute_reply":"2024-01-20T23:13:29.122273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale geo data\ndf_sensor_working = df_sensor.copy() \ndf_sensor_working[['x', 'y', 'z']] = df_sensor_working[['x', 'y', 'z']] / 500\ndf_sensor_working","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:13:29.125778Z","iopub.execute_input":"2024-01-20T23:13:29.126234Z","iopub.status.idle":"2024-01-20T23:13:29.159660Z","shell.execute_reply.started":"2024-01-20T23:13:29.126183Z","shell.execute_reply":"2024-01-20T23:13:29.157812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.mkdir('/kaggle/working/train_subset/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define paths\ndest = '/kaggle/working/train_subset/'\ncurr = '/kaggle/input/icecube-neutrinos-in-deep-ice/train/'\n\nfor i in range(50):\n    o = random.randrange(1, 661)\n    processing = f\"{curr}batch_{o}.parquet\"\n    \n    # load data\n    df = pd.read_parquet(processing)\n    \n    # filter events with max 200 pulses\n    pulse_counts = df.index.value_counts()\n    valid_events = pulse_counts[pulse_counts <= 200].index\n    df_working = df[df.index.isin(valid_events)].copy()  # Create a copy here\n    \n    # fetch id of relevant sensors \n    sensors = df_working['sensor_id'].unique()\n    \n    # scale time and charge\n    df_working['time'] = (df_working['time'] - 1e4) / 115\n    df_working['charge'] = np.where(df_working['charge'] > 0, np.log10(df_working['charge']) / 3, 0)\n    \n    # fetch geometric data from the sensors df\n    geo_data = df_sensor_working[df_sensor_working['sensor_id'].isin(sensors)]\n    coords = geo_data[['sensor_id', 'x', 'y', 'z']]  # Include 'sensor_id' for merging\n\n    # reset index, wont need that \n    df_working.reset_index(drop=True, inplace=True)\n\n    # merge and save dataframe\n    processed_df = pd.merge(df_working, coords, on='sensor_id', how='left')\n    processed_df.drop('sensor_id', axis=1, inplace=True)\n    processed_df.to_parquet(f\"{dest}batch_{o}.parquet\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:15:53.131118Z","iopub.execute_input":"2024-01-20T23:15:53.131618Z","iopub.status.idle":"2024-01-20T23:25:03.627241Z","shell.execute_reply.started":"2024-01-20T23:15:53.131577Z","shell.execute_reply":"2024-01-20T23:25:03.625999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_parquet('/kaggle/working/train_subset/batch_419.parquet')\ntest.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:25:32.111237Z","iopub.execute_input":"2024-01-20T23:25:32.111825Z","iopub.status.idle":"2024-01-20T23:25:32.817259Z","shell.execute_reply.started":"2024-01-20T23:25:32.111778Z","shell.execute_reply":"2024-01-20T23:25:32.816294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Excellent. Elementary features have been extracted and preprocessed for 50 batches. Next, we must obtain node homophility of (x, y, z, t). We will do this for each batch, using a kNN graph.","metadata":{}},{"cell_type":"code","source":"# choosing an approriate number of clusters using the elbow method i.e. the point at which the within-cluster sum of squares\n# stops increasing rapidly\n\n# man this took years\ndf = pd.read_parquet('/kaggle/working/train_subset/batch_419.parquet')\nfeatures = df[['x', 'y', 'z', 'time']]\nwcss = []\n\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters=i, n_init=10, random_state=0)\n    kmeans.fit(features)\n    wcss.append(kmeans.inertia_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(1, 11), wcss)\nplt.title('WCSS vs Number of Clusters')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.grid()\n# Let's go with 7","metadata":{"execution":{"iopub.status.busy":"2024-01-21T00:01:07.727908Z","iopub.execute_input":"2024-01-21T00:01:07.728745Z","iopub.status.idle":"2024-01-21T00:01:08.062581Z","shell.execute_reply.started":"2024-01-21T00:01:07.728702Z","shell.execute_reply":"2024-01-21T00:01:08.061312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def calc_homophily_ratio(nodes:pd.DataFrame, group_column:str) -> float:\n#     # create edges \n#     edges = pd.merge(node, nodes, on=group_column)\n\n#     # calculate homophily \n#     total_edges = len(edges)\n#     same_group_edges = len(edges[edges['group_x'] == edges['group_y']])\n#     homophily_ratio = same_group_edges / total_edges\n\n#     return homophily_ratio","metadata":{"execution":{"iopub.status.busy":"2024-01-21T00:02:04.543990Z","iopub.execute_input":"2024-01-21T00:02:04.544487Z","iopub.status.idle":"2024-01-21T00:02:04.552110Z","shell.execute_reply.started":"2024-01-21T00:02:04.544447Z","shell.execute_reply":"2024-01-21T00:02:04.550700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def process_file(file):\n#     df = pd.read_parquet(f\"{dest}{file}\")\n#     features = df[['x', 'y', 'z', 'time']]\n    \n#     kmeans = KMeans(n_clusters=7)\n#     df['group'] = kmeans.fit_predict(features)\n    \n#     ratio = calc_homophily_ratio(df, 'group')\n#     return file, ratio\n\n# global_stats = {}\n# for file in os.listdir(dest):\n#     file, ratio = process_file(file)\n#     global_stats[file] = ratio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will skip the global statics extraction, as I am still trying to understand excatly what they mean. I will jump to building some of the components of the model. We start with the feed forward network (Feed Forward -> Add & Norm).","metadata":{}},{"cell_type":"code","source":"# Feed Forward followed by Add & Norm\n\nclass FeedForward(tf.keras.layers.Layer):\n    def __init__(self, d_model, dff, dropout_rate=0.1):\n        super().__init__()\n        self.seq = tf.keras.Sequential([\n          tf.keras.layers.Dense(dff, activation='relu'),\n          tf.keras.layers.Dense(d_model),\n          tf.keras.layers.Dropout(dropout_rate)\n        ])\n        self.add = tf.keras.layers.Add()\n        self.layer_norm = tf.keras.layers.LayerNormalization()\n        \n    def call(self, x):\n        x = self.add([x, self.seq(x)])\n        x = self.layer_norm(x) \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-23T19:05:20.852616Z","iopub.execute_input":"2024-01-23T19:05:20.853041Z","iopub.status.idle":"2024-01-23T19:05:20.862241Z","shell.execute_reply.started":"2024-01-23T19:05:20.853007Z","shell.execute_reply":"2024-01-23T19:05:20.860956Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Multi-Head Attention followed by Add & Norm\n\nclass SelfAttention(BaseAttention):\n    def __init__(self, **kwargs):\n        super().__init__()\n        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n        self.layernorm = tf.keras.layers.LayerNormalization()\n        self.add = tf.keras.layers.Add()\n    \n    def call(self, x):\n        attn_output = self.mha(\n            query=x,\n            value=x,\n            key=x)\n        x = self.add([x, attn_output])\n        x = self.layernorm(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]}]}